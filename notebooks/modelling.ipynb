{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model\n",
    "\n",
    "- We don't have returns after 2022 Jan. \n",
    "- We have data until 2022 Sept.\n",
    "\n",
    "- For model training:\n",
    "    - Testing period --> 2021 June - 2022 Jan\n",
    "    - Train period: 2017 June - 2021 June (3 years)\n",
    "    One stock per line. Aggregate all data into one row\n",
    "\n",
    "- For Inference:\n",
    "    - Infer for periods between 2019 Sept. - 2022 Sept.\n",
    "    - This will give us the returns for 2022 Sept. until 2023 March. \n",
    "    - Choose the top 15 stocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import src.data.preprocessing as pr\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:7: DtypeWarning: Columns (8,17,26,33,34,66,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,252,253,255,257,259,261,263,265,267,269,270,271,272,273,274,275,276,277,278,279,280,284,285,286,290) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, delimiter=\";\", parse_dates=date_cols).iloc[:, 1:]\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Call ffill before calling pct_change to retain current behavior and silence this warning.\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ROI'] = (df['capitalExpenditure']/df['netIncome']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['profit_margin'] = (df['netIncome'] / df['revenue']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['market_value_per_share'] = df['marketCapitalization'] / \\\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['pe_ratio'] = df['market_value_per_share'] / df['eps']\n"
     ]
    }
   ],
   "source": [
    "df = pr.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quarter\n",
       "1    1407\n",
       "3    1407\n",
       "6    1407\n",
       "9    1407\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.year==2022].groupby(\"quarter\").apply(lambda x: len(x.index.get_level_values(1).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        symbol  \n",
       "2022-01-31  0O9.F        11.952000\n",
       "            0QF.F       148.268000\n",
       "            217A.F        7.990000\n",
       "            22UA.F      156.159998\n",
       "            2CRSI.PA      4.443000\n",
       "                           ...    \n",
       "            XIL.PA       38.820000\n",
       "            XIOR.BR      48.390000\n",
       "            YATRA.AS      3.300000\n",
       "            YK6B.F       15.350000\n",
       "            ZEL.NZ        3.598000\n",
       "Name: close, Length: 1387, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.year==2022].close.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Only keep stocks that are trading in Euros\n",
    "currency_by_stock = df[\"reportedCurrency\"].groupby(\"symbol\").apply(lambda x:x.dropna()[0] if len(x.dropna()) > 0 else np.nan)\n",
    "euro_stocks = currency_by_stock[currency_by_stock==\"EUR\"].index\n",
    "idx = pd.IndexSlice[:, euro_stocks]\n",
    "df = df.loc[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1995-01-31', '1995-01-31', '1995-01-31', '1995-01-31',\n",
       "               '1995-01-31', '1995-01-31', '1995-01-31', '1995-01-31',\n",
       "               '1995-01-31', '1995-01-31',\n",
       "               ...\n",
       "               '2022-09-30', '2022-09-30', '2022-09-30', '2022-09-30',\n",
       "               '2022-09-30', '2022-09-30', '2022-09-30', '2022-09-30',\n",
       "               '2022-09-30', '2022-09-30'],\n",
       "              dtype='datetime64[ns]', name='date', length=157584, freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">quarter</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>market_value_per_share</th>\n",
       "      <th colspan=\"9\" halign=\"left\">pe_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>2019-06-30</th>\n",
       "      <th>2019-09-30</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <th>2020-03-31</th>\n",
       "      <th>2020-06-30</th>\n",
       "      <th>2020-09-30</th>\n",
       "      <th>2021-01-31</th>\n",
       "      <th>2021-03-31</th>\n",
       "      <th>2021-06-30</th>\n",
       "      <th>2019-06-30</th>\n",
       "      <th>...</th>\n",
       "      <th>2021-06-30</th>\n",
       "      <th>2019-06-30</th>\n",
       "      <th>2019-09-30</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <th>2020-03-31</th>\n",
       "      <th>2020-06-30</th>\n",
       "      <th>2020-09-30</th>\n",
       "      <th>2021-01-31</th>\n",
       "      <th>2021-03-31</th>\n",
       "      <th>2021-06-30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0O9.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0QF.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217A.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>-7.471373</td>\n",
       "      <td>-11.326101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.052288</td>\n",
       "      <td>-1.386686</td>\n",
       "      <td>22.112379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-46.419172</td>\n",
       "      <td>6.104760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22UA.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>189.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99.093458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-214.101854</td>\n",
       "      <td>-159.552784</td>\n",
       "      <td>-66.863636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.719828</td>\n",
       "      <td>16.571804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2CRSI.PA</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XIOR.BR</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YATRA.AS</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-127.790430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-103.920325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YK6B.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZEL.NZ</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZEN.BR</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows × 2601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            quarter                                                         \\\n",
       "date     2019-06-30 2019-09-30 2020-01-31 2020-03-31 2020-06-30 2020-09-30   \n",
       "symbol                                                                       \n",
       "0O9.F             6          9          1          3          6          9   \n",
       "0QF.F             6          9          1          3          6          9   \n",
       "217A.F            6          9          1          3          6          9   \n",
       "22UA.F            6          9          1          3          6          9   \n",
       "2CRSI.PA          6          9          1          3          6          9   \n",
       "...             ...        ...        ...        ...        ...        ...   \n",
       "XIOR.BR           6          9          1          3          6          9   \n",
       "YATRA.AS          6          9          1          3          6          9   \n",
       "YK6B.F            6          9          1          3          6          9   \n",
       "ZEL.NZ            6          9          1          3          6          9   \n",
       "ZEN.BR            6          9          1          3          6          9   \n",
       "\n",
       "                                                week  ...  \\\n",
       "date     2021-01-31 2021-03-31 2021-06-30 2019-06-30  ...   \n",
       "symbol                                                ...   \n",
       "0O9.F             1          3          6         26  ...   \n",
       "0QF.F             1          3          6         26  ...   \n",
       "217A.F            1          3          6         26  ...   \n",
       "22UA.F            1          3          6         26  ...   \n",
       "2CRSI.PA          1          3          6         26  ...   \n",
       "...             ...        ...        ...        ...  ...   \n",
       "XIOR.BR           1          3          6         26  ...   \n",
       "YATRA.AS          1          3          6         26  ...   \n",
       "YK6B.F            1          3          6         26  ...   \n",
       "ZEL.NZ            1          3          6         26  ...   \n",
       "ZEN.BR            1          3          6         26  ...   \n",
       "\n",
       "         market_value_per_share   pe_ratio                                    \\\n",
       "date                 2021-06-30 2019-06-30 2019-09-30 2020-01-31  2020-03-31   \n",
       "symbol                                                                         \n",
       "0O9.F                       NaN        NaN        NaN        NaN         NaN   \n",
       "0QF.F                       NaN        NaN        NaN        NaN         NaN   \n",
       "217A.F                19.200001  -7.471373 -11.326101        NaN  -10.052288   \n",
       "22UA.F               189.250000        NaN -99.093458        NaN -214.101854   \n",
       "2CRSI.PA                    NaN        NaN        NaN        NaN         NaN   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "XIOR.BR                     NaN        NaN        NaN        NaN         NaN   \n",
       "YATRA.AS                    NaN        NaN        NaN        NaN -127.790430   \n",
       "YK6B.F                      NaN        NaN        NaN        NaN         NaN   \n",
       "ZEL.NZ                      NaN        NaN        NaN        NaN         NaN   \n",
       "ZEN.BR                      NaN        NaN        NaN        NaN         NaN   \n",
       "\n",
       "                                                                   \n",
       "date      2020-06-30 2020-09-30 2021-01-31  2021-03-31 2021-06-30  \n",
       "symbol                                                             \n",
       "0O9.F            NaN        NaN        NaN         NaN        NaN  \n",
       "0QF.F            NaN        NaN        NaN         NaN        NaN  \n",
       "217A.F     -1.386686  22.112379        NaN  -46.419172   6.104760  \n",
       "22UA.F   -159.552784 -66.863636        NaN   19.719828  16.571804  \n",
       "2CRSI.PA         NaN        NaN        NaN         NaN        NaN  \n",
       "...              ...        ...        ...         ...        ...  \n",
       "XIOR.BR          NaN        NaN        NaN         NaN        NaN  \n",
       "YATRA.AS         NaN        NaN        NaN -103.920325        NaN  \n",
       "YK6B.F           NaN        NaN        NaN         NaN        NaN  \n",
       "ZEL.NZ           NaN        NaN        NaN         NaN        NaN  \n",
       "ZEN.BR           NaN        NaN        NaN         NaN        NaN  \n",
       "\n",
       "[1407 rows x 2601 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set train and validation dates\n",
    "train_dates = {\"start\": dt.datetime(2019, 6, 30), \"end\": dt.datetime(2021, 6, 30)}\n",
    "val_dates = {\"start\": dt.datetime(2022, 1, 1), \"end\": dt.datetime(2023, 1, 31)}\n",
    "\n",
    "X_train = df.loc[train_dates[\"start\"]: train_dates[\"end\"]]\n",
    "X_train = X_train.unstack(level=0).drop(\"year\", axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "return\n",
       " 0.000000    4242\n",
       "-0.041667       2\n",
       " 0.090909       2\n",
       "-0.214286       2\n",
       " 0.230950       1\n",
       "             ... \n",
       " 0.031020       1\n",
       " 0.376026       1\n",
       "-0.018137       1\n",
       " 0.526165       1\n",
       " 0.055132       1\n",
       "Name: count, Length: 1375, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train = \n",
    "test_per_rets = df.loc[val_dates[\"start\"]: val_dates[\"end\"], \"return\"]\n",
    "test_per_rets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop stocks with missing returns for this period\n",
    "to_drop = test_per_rets[test_per_rets.isna()].index.get_level_values(\"symbol\").unique()\n",
    "\n",
    "# drop stocks that traded under 1$ in the period\n",
    "under_1 = X_train['close'].groupby(level=\"symbol\").apply(lambda x: (x<1).any(axis=1)).droplevel(1)\n",
    "to_drop = to_drop.union(under_1[under_1].index).unique()\n",
    "\n",
    "X_train = X_train.drop(to_drop)\n",
    "y_train = test_per_rets.drop(to_drop, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(np.setdiff1d(X_train.index, y_train.index.get_level_values(1)))\n",
    "print(np.setdiff1d(y_train.index.get_level_values(1), X_train.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teuta\\AppData\\Local\\Temp\\ipykernel_16956\\2731682971.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train = y_train.groupby(level=1, group_keys=False).apply(lambda x: x.cumprod()[-1])\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.groupby(level=1, group_keys=False).apply(lambda x: x.cumprod()[-1])\n",
    "\n",
    "assert all(X_train.index == y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last checks and drops on columns\n",
    "X_train = X_train.select_dtypes(exclude=[\"object\", \"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    2547\n",
       "int64        18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991523339370572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">quarter</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>market_value_per_share</th>\n",
       "      <th colspan=\"9\" halign=\"left\">pe_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>2018-06-30</th>\n",
       "      <th>2018-09-30</th>\n",
       "      <th>2019-01-31</th>\n",
       "      <th>2019-03-31</th>\n",
       "      <th>2019-06-30</th>\n",
       "      <th>2019-09-30</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <th>2020-03-31</th>\n",
       "      <th>2020-06-30</th>\n",
       "      <th>2018-06-30</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-06-30</th>\n",
       "      <th>2018-06-30</th>\n",
       "      <th>2018-09-30</th>\n",
       "      <th>2019-01-31</th>\n",
       "      <th>2019-03-31</th>\n",
       "      <th>2019-06-30</th>\n",
       "      <th>2019-09-30</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <th>2020-03-31</th>\n",
       "      <th>2020-06-30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0O9.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0QF.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217A.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>-9.446522</td>\n",
       "      <td>-33.968887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.356871</td>\n",
       "      <td>-7.471373</td>\n",
       "      <td>-11.326101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.052288</td>\n",
       "      <td>-1.386686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22UA.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>60.630058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99.093458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-214.101854</td>\n",
       "      <td>-159.552784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2CRSI.PA</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XIOR.BR</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YATRA.AS</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.230335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-127.790430</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YK6B.F</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZEL.NZ</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZEN.BR</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows × 2601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            quarter                                                         \\\n",
       "date     2018-06-30 2018-09-30 2019-01-31 2019-03-31 2019-06-30 2019-09-30   \n",
       "symbol                                                                       \n",
       "0O9.F             6          9          1          3          6          9   \n",
       "0QF.F             6          9          1          3          6          9   \n",
       "217A.F            6          9          1          3          6          9   \n",
       "22UA.F            6          9          1          3          6          9   \n",
       "2CRSI.PA          6          9          1          3          6          9   \n",
       "...             ...        ...        ...        ...        ...        ...   \n",
       "XIOR.BR           6          9          1          3          6          9   \n",
       "YATRA.AS          6          9          1          3          6          9   \n",
       "YK6B.F            6          9          1          3          6          9   \n",
       "ZEL.NZ            6          9          1          3          6          9   \n",
       "ZEN.BR            6          9          1          3          6          9   \n",
       "\n",
       "                                                week  ...  \\\n",
       "date     2020-01-31 2020-03-31 2020-06-30 2018-06-30  ...   \n",
       "symbol                                                ...   \n",
       "0O9.F             1          3          6         26  ...   \n",
       "0QF.F             1          3          6         26  ...   \n",
       "217A.F            1          3          6         26  ...   \n",
       "22UA.F            1          3          6         26  ...   \n",
       "2CRSI.PA          1          3          6         26  ...   \n",
       "...             ...        ...        ...        ...  ...   \n",
       "XIOR.BR           1          3          6         26  ...   \n",
       "YATRA.AS          1          3          6         26  ...   \n",
       "YK6B.F            1          3          6         26  ...   \n",
       "ZEL.NZ            1          3          6         26  ...   \n",
       "ZEN.BR            1          3          6         26  ...   \n",
       "\n",
       "         market_value_per_share   pe_ratio                                    \\\n",
       "date                 2020-06-30 2018-06-30 2018-09-30 2019-01-31  2019-03-31   \n",
       "symbol                                                                         \n",
       "0O9.F                       NaN        NaN        NaN        NaN         NaN   \n",
       "0QF.F                       NaN        NaN        NaN        NaN         NaN   \n",
       "217A.F                20.799999  -9.446522 -33.968887        NaN  137.356871   \n",
       "22UA.F                60.630058        NaN        NaN        NaN         NaN   \n",
       "2CRSI.PA                    NaN        NaN        NaN        NaN         NaN   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "XIOR.BR                     NaN        NaN        NaN        NaN         NaN   \n",
       "YATRA.AS                    NaN        NaN        NaN        NaN    8.230335   \n",
       "YK6B.F                      NaN        NaN        NaN        NaN         NaN   \n",
       "ZEL.NZ                      NaN        NaN        NaN        NaN         NaN   \n",
       "ZEN.BR                      NaN        NaN        NaN        NaN         NaN   \n",
       "\n",
       "                                                                   \n",
       "date     2019-06-30 2019-09-30 2020-01-31  2020-03-31  2020-06-30  \n",
       "symbol                                                             \n",
       "0O9.F           NaN        NaN        NaN         NaN         NaN  \n",
       "0QF.F           NaN        NaN        NaN         NaN         NaN  \n",
       "217A.F    -7.471373 -11.326101        NaN  -10.052288   -1.386686  \n",
       "22UA.F          NaN -99.093458        NaN -214.101854 -159.552784  \n",
       "2CRSI.PA        NaN        NaN        NaN         NaN         NaN  \n",
       "...             ...        ...        ...         ...         ...  \n",
       "XIOR.BR         NaN        NaN        NaN         NaN         NaN  \n",
       "YATRA.AS        NaN        NaN        NaN -127.790430         NaN  \n",
       "YK6B.F          NaN        NaN        NaN         NaN         NaN  \n",
       "ZEL.NZ          NaN        NaN        NaN         NaN         NaN  \n",
       "ZEN.BR          NaN        NaN        NaN         NaN         NaN  \n",
       "\n",
       "[1407 rows x 2601 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_dates = {\"start\": dt.datetime(2018, 6, 30), \"end\": dt.datetime(2020, 6, 30)}\n",
    "predicted_dates = {\"start\": dt.datetime(2020, 6, 30), \"end\": dt.datetime(2021, 1, 31)}\n",
    "\n",
    "X_test = df.loc[infer_dates[\"start\"]: infer_dates[\"end\"]]\n",
    "X_test = X_test.unstack(level=0).drop(\"year\", axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.select_dtypes(exclude=[\"object\", \"datetime\"])\n",
    "assert len(X_train.columns) == len(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.Series(model.predict(X_test), X_test.index)\n",
    "top20_stocks = y_pred.sort_values()[-20:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teuta\\AppData\\Local\\Temp\\ipykernel_20540\\1055454902.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_test = y_test.groupby(level=1, group_keys=False).apply(lambda x: x.cumprod()[-1])\n"
     ]
    }
   ],
   "source": [
    "y_test = df.loc[predicted_dates[\"start\"]: predicted_dates[\"end\"], \"return\"]\n",
    "y_test = y_test.groupby(level=1, group_keys=False).apply(lambda x: x.cumprod()[-1])\n",
    "y_test = y_test[y_test.index.isin(y_pred.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE).\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): Actual (true) values.\n",
    "    y_pred (array-like): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The RMSE.\n",
    "    \"\"\"\n",
    "    squared_errors = (y_true - y_pred) ** 2\n",
    "    mean_squared_error = squared_errors.mean()\n",
    "    rmse = np.sqrt(mean_squared_error)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19169965319687007"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({\"y_test\":y_test, \"y_pred\": y_pred})#.loc[top20_stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"diff\"] = preds[\"y_test\"] - preds[\"y_pred\"]\n",
    "# preds.iloc[np.where((preds[\"diff\"] < 0.01) & (preds[\"diff\"] > -0.01))]\n",
    "preds.loc[top20_stocks].to_csv(\"top20_stocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\teuta\\\\Desktop\\\\vscode\\\\quinten-stock-prediction'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import train\n",
    "from src.models import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train = dt.datetime.strptime(\"2016/01/31\", \"%Y/%m/%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:7: DtypeWarning: Columns (8,17,26,33,34,66,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,252,253,255,257,259,261,263,265,267,269,270,271,272,273,274,275,276,277,278,279,280,284,285,286,290) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, delimiter=\";\", parse_dates=date_cols).iloc[:, 1:]\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Call ffill before calling pct_change to retain current behavior and silence this warning.\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ROI'] = (df['capitalExpenditure']/df['netIncome']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['profit_margin'] = (df['netIncome'] / df['revenue']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['market_value_per_share'] = df['marketCapitalization'] / \\\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['pe_ratio'] = df['market_value_per_share'] / df['eps']\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\models\\train.py:53: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train = y_train.groupby(level=1, group_keys=False).apply(lambda x: x.cumprod()[-1])\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [20:54:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "start_train = dt.datetime.strptime(\"2016/01/31\", \"%Y/%m/%d\")\n",
    "end_train = dt.datetime.strptime(\"2018/01/31\", \"%Y/%m/%d\")\n",
    "start_val = dt.datetime.strptime(\"2018/01/31\", \"%Y/%m/%d\")\n",
    "end_val = dt.datetime.strptime(\"2018/06/30\", \"%Y/%m/%d\")\n",
    "\n",
    "\n",
    "train.train(start_train, end_train, start_val, end_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:7: DtypeWarning: Columns (8,17,26,33,34,66,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,252,253,255,257,259,261,263,265,267,269,270,271,272,273,274,275,276,277,278,279,280,284,285,286,290) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, delimiter=\";\", parse_dates=date_cols).iloc[:, 1:]\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Call ffill before calling pct_change to retain current behavior and silence this warning.\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ROI'] = (df['capitalExpenditure']/df['netIncome']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['profit_margin'] = (df['netIncome'] / df['revenue']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['market_value_per_share'] = df['marketCapitalization'] / \\\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['pe_ratio'] = df['market_value_per_share'] / df['eps']\n"
     ]
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from src.models import train\n",
    "from src.models import inference\n",
    "import src.data.preprocessing as pr\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "df = pr.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2015, 1, 31, 0, 0), datetime.datetime(2015, 6, 30, 0, 0), datetime.datetime(2016, 1, 31, 0, 0), datetime.datetime(2016, 6, 30, 0, 0), datetime.datetime(2017, 1, 31, 0, 0)] \n",
      " [datetime.datetime(2017, 1, 31, 0, 0), datetime.datetime(2017, 6, 30, 0, 0), datetime.datetime(2018, 1, 31, 0, 0), datetime.datetime(2018, 6, 30, 0, 0), datetime.datetime(2019, 1, 31, 0, 0)] \n",
      " [datetime.datetime(2017, 1, 31, 0, 0), datetime.datetime(2017, 6, 30, 0, 0), datetime.datetime(2018, 1, 31, 0, 0), datetime.datetime(2018, 6, 30, 0, 0), datetime.datetime(2019, 1, 31, 0, 0)] \n",
      " [datetime.datetime(2017, 6, 30, 0, 0), datetime.datetime(2018, 1, 30, 0, 0), datetime.datetime(2018, 6, 30, 0, 0), datetime.datetime(2019, 1, 30, 0, 0), datetime.datetime(2019, 6, 30, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "# get dates starting from 2015 Jan\n",
    "train_duration_months = 24\n",
    "validation_duration_months = 6\n",
    "gap = 0\n",
    "\n",
    "train_start_dates = [dt.datetime(2015, 1, 31) + relativedelta(months=validation_duration_months*i) for i in range(5)]\n",
    "train_start_dates = [i - relativedelta(months=1) if i.month==7 else i  for i in train_start_dates]\n",
    "train_end_dates = [i + relativedelta(months=24) for i in train_start_dates]\n",
    "val_start_dates = [i for i in train_end_dates]\n",
    "#val_start_dates = [i + relativedelta(months=1) if i.month==5 else i for i in val_start_dates]\n",
    "val_end_dates = [i + relativedelta(months=validation_duration_months) for i in val_start_dates]\n",
    "val_end_dates = [i + relativedelta(months=1) if i.month==12 else i - relativedelta(months=1) for i in val_end_dates]\n",
    "\n",
    "print(train_start_dates, \"\\n\", train_end_dates, \"\\n\", val_start_dates,\"\\n\" , val_end_dates)\n",
    "\n",
    "\n",
    "inference_start_dates = [i + relativedelta(months=6) for i in train_end_dates]\n",
    "inference_start_dates = [i - relativedelta(months=1) if i.month == 7 else i+relativedelta(months=1) for i in inference_start_dates]\n",
    "inference_end_dates = [i + relativedelta(months=24) for i in inference_start_dates]\n",
    "inference_end_dates = [i + relativedelta(months=1) if i.month == 12 else i for i in inference_end_dates]\n",
    "\n",
    "predicted_start_dates = [i + relativedelta(months=6) for i in inference_end_dates]\n",
    "predicted_start_dates = [i - relativedelta(months=1) if i.month == 7 else i+relativedelta(months=1) for i in predicted_start_dates]\n",
    "predicted_end_dates = [i + relativedelta(months=6) for i in predicted_start_dates]\n",
    "predicted_end_dates = [i - relativedelta(months=1) if i.month == 7 else i+relativedelta(months=1) for i in predicted_end_dates]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 6, 30, 0, 0), datetime.datetime(2018, 1, 30, 0, 0), datetime.datetime(2018, 6, 30, 0, 0), datetime.datetime(2019, 1, 30, 0, 0), datetime.datetime(2019, 6, 30, 0, 0)]\n",
      "[datetime.datetime(2019, 6, 30, 0, 0), datetime.datetime(2020, 1, 30, 0, 0), datetime.datetime(2020, 6, 30, 0, 0), datetime.datetime(2021, 1, 30, 0, 0), datetime.datetime(2021, 6, 30, 0, 0)]\n",
      "[datetime.datetime(2020, 1, 30, 0, 0), datetime.datetime(2020, 6, 30, 0, 0), datetime.datetime(2021, 1, 30, 0, 0), datetime.datetime(2021, 6, 30, 0, 0), datetime.datetime(2022, 1, 30, 0, 0)]\n",
      "[datetime.datetime(2020, 6, 30, 0, 0), datetime.datetime(2021, 1, 30, 0, 0), datetime.datetime(2021, 6, 30, 0, 0), datetime.datetime(2022, 1, 30, 0, 0), datetime.datetime(2022, 6, 30, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(inference_start_dates)\n",
    "print(inference_end_dates)\n",
    "print(predicted_start_dates)\n",
    "print(predicted_end_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:7: DtypeWarning: Columns (8,17,26,33,34,66,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,252,253,255,257,259,261,263,265,267,269,270,271,272,273,274,275,276,277,278,279,280,284,285,286,290) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, delimiter=\";\", parse_dates=date_cols).iloc[:, 1:]\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Call ffill before calling pct_change to retain current behavior and silence this warning.\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ROI'] = (df['capitalExpenditure']/df['netIncome']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['profit_margin'] = (df['netIncome'] / df['revenue']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['market_value_per_share'] = df['marketCapitalization'] / \\\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['pe_ratio'] = df['market_value_per_share'] / df['eps']\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [21:12:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\models\\inference.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_test = y_test.groupby(level=1, group_keys=False).apply(lambda x: x.cumprod()[-1])\n",
      "C:\\Users\\teuta\\AppData\\Local\\Temp\\ipykernel_16748\\1760996290.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, res.reset_index(drop=True)])\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:7: DtypeWarning: Columns (8,17,26,33,34,66,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,252,253,255,257,259,261,263,265,267,269,270,271,272,273,274,275,276,277,278,279,280,284,285,286,290) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, delimiter=\";\", parse_dates=date_cols).iloc[:, 1:]\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Call ffill before calling pct_change to retain current behavior and silence this warning.\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"return\"] = df[\"close\"].groupby(level=\"symbol\", group_keys=False).apply(lambda x: x.pct_change())\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ROI'] = (df['capitalExpenditure']/df['netIncome']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['profit_margin'] = (df['netIncome'] / df['revenue']) * 100\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['market_value_per_share'] = df['marketCapitalization'] / \\\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\data\\preprocessing.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['pe_ratio'] = df['market_value_per_share'] / df['eps']\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\models\\train.py:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train = y_train.groupby(level=1, group_keys=False).apply(lambda x: x.cumprod()[-1])\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [21:13:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 2565, got 2280",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\notebooks\\modelling.ipynb Cell 41\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/teuta/Desktop/vscode/quinten-stock-prediction/notebooks/modelling.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(train_start_dates[i])[:\u001b[39m10\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(train_end_dates[i])[:\u001b[39m10\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/teuta/Desktop/vscode/quinten-stock-prediction/notebooks/modelling.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mtrain(train_start_dates[i], train_end_dates[i], val_start_dates[i], val_end_dates[i],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/teuta/Desktop/vscode/quinten-stock-prediction/notebooks/modelling.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model_name\u001b[39m=\u001b[39mmodel_name)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/teuta/Desktop/vscode/quinten-stock-prediction/notebooks/modelling.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m res \u001b[39m=\u001b[39m inference\u001b[39m.\u001b[39;49minference(inference_start_dates[i], inference_end_dates[i], predicted_start_dates[i], predicted_end_dates[i],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/teuta/Desktop/vscode/quinten-stock-prediction/notebooks/modelling.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                     model, df\u001b[39m=\u001b[39;49mdf)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/teuta/Desktop/vscode/quinten-stock-prediction/notebooks/modelling.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([results, res\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)])\n",
      "File \u001b[1;32mc:\\Users\\teuta\\Desktop\\vscode\\quinten-stock-prediction\\src\\models\\inference.py:21\u001b[0m, in \u001b[0;36minference\u001b[1;34m(inference_start, inference_end, prediction_start, prediction_end, model, df)\u001b[0m\n\u001b[0;32m     19\u001b[0m X_test \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39munstack(level\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39myear\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m X_test \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mselect_dtypes(exclude\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     22\u001b[0m y_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(model\u001b[39m.\u001b[39mpredict(X_test), X_test\u001b[39m.\u001b[39mindex)\n\u001b[0;32m     23\u001b[0m top20_stocks \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39msort_values()[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]\u001b[39m.\u001b[39mindex\n",
      "File \u001b[1;32mc:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1164\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1163\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1164\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[0;32m   1165\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1166\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1167\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1168\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m   1169\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1170\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1171\u001b[0m         )\n\u001b[0;32m   1172\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1173\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\teuta\\Desktop\\vscode\\.venv\\Lib\\site-packages\\xgboost\\core.py:2426\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2422\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2423\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2424\u001b[0m         )\n\u001b[0;32m   2425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m-> 2426\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2427\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2428\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2429\u001b[0m         )\n\u001b[0;32m   2431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   2432\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 2565, got 2280"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=[\"y_test\", \"y_pred\"])\n",
    "for i in range(len(train_start_dates)):\n",
    "    model_name = f\"{str(train_start_dates[i])[:10]}: {str(train_end_dates[i])[:10]}\"\n",
    "    model = train.train(train_start_dates[i], train_end_dates[i], val_start_dates[i], val_end_dates[i],\n",
    "        model_name=model_name)\n",
    "    \n",
    "    res = inference.inference(inference_start_dates[i], inference_end_dates[i], predicted_start_dates[i], predicted_end_dates[i],\n",
    "                        model, df=df)\n",
    "    results = pd.concat([results, res.reset_index(drop=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004512</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.197800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.011700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.080219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.110884</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.024220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.023642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.004020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test  y_pred\n",
       "0        NaN     0.0\n",
       "1  -0.004512     0.0\n",
       "2   0.156022     0.0\n",
       "3  -0.003902     0.0\n",
       "4  -0.001176     0.0\n",
       "5  -0.000453     0.0\n",
       "6   0.000968     0.0\n",
       "7   0.003350     0.0\n",
       "8  -0.002042     0.0\n",
       "9  -0.197800     0.0\n",
       "10 -0.011700     0.0\n",
       "11  0.080219     0.0\n",
       "12  0.110884     0.0\n",
       "13 -0.024220     0.0\n",
       "14 -0.023642     0.0\n",
       "15  0.001344     0.0\n",
       "16  0.003732     0.0\n",
       "17 -0.004020     0.0\n",
       "18 -0.000000     0.0\n",
       "19 -0.002496     0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
